
********************************(HIVE 3)***********************************************

hadoop fs -ls /user/hive/warehouse/hive_class

vim sales_data.csv

cp sales_data.csv /tmp/hive_class

hive

use hive_class_b1;

create table sales_data_parquet
(
product_type string,
total_sale int)
row format delimited 
fields terminated by ','
stored as parquet;

describe formatted sales_data_parquet

load data local inpath 'file:///tmp/data/sales_data.csv' into table sales_data_parquet;

# command to create identical table
create table sales_data_v2_bkup as select * from sales_data_v2;

# describe command for a table
describe extended sales_data_v2;


# create a table which will store data in parquet

create table sales_data_pq_final                                                                                                        
    > (                                                                                                                                       
    > product_type string,                                                                                                                    
    > total_sales int                                                                                                                         
    > )                                                                                                                                       
    > stored as parquet;  
    
# load data in parquet file
from sales_data_v2 insert overwrite table sales_data_pq_final select *;


*****************************************(HIVE SEPT 11)***********************************************

-- Use this command to get the details about the serialization and de-serialization
describe data patientdb_parquet;

-- Create a file
vim csv_file.csv

-- Copy it into the local
cp csv_file.csv /tmp/patient_db

-- create table
create table csv_table (
name string,
location string
)
row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
with serdeproperties(
"seperatorChar" = ",",
"quoteChar" = "\"",
"escapeChar" = "\\"
)
stored as textfile
tblprproperties ("skipheader.line.count" = "1");


describe formatted csv_table;

load data local inpath 'file:///tmp/patient_data/csv_file.csv' into table csv_table;

-- download hive catalog jar file , if serde libraries are not imported
https://repo1.maven.org/maven2/org/apache/hive/hcatalog/hive-hcatalog-core/0.14.0/

-- add jar file into your hive shell
hive> add jar /tmp/hive_class/hive-hcatalog-core-0.14.0.jar;

-- To demonstrate using the JSON files

vim json_file.json

cp json_file.json /tmp/patient_data/

--open hive terminal

add jar file:///tmp/patient_data/hive-hcatalog-

create table json_table
(
name string,
id int,
skills array<skills>
)
row format serde 'org.apache.hive.hcatalog.data.JsonSerDe'
stored as textfile;

load data file inpath 'file:///tmp/patient_data/json_file.json' into table json_table;

set hive.cli.print.header = True

# create csv table for sales data

create table sales_order_data_csv_v1
(
ORDERNUMBER int,
QUANTITYORDERED int,
PRICEEACH float,
ORDERLINENUMBER int,
SALES float,
STATUS string,
QTR_ID int,
MONTH_ID int,
YEAR_ID int,
PRODUCTLINE string,
MSRP int,
PRODUCTCODE string,
PHONE string,
CITY string,
STATE string,
POSTALCODE string,
COUNTRY string,
TERRITORY string,
CONTACTLASTNAME string,
CONTACTFIRSTNAME string,
DEALSIZE string
)
row format delimited
fields terminated by ','
tblproperties("skip.header.line.count"="1")
; 

# load sales_order_data.csv data into above mentioned tables
load data local inpath 'file:///tmp/sales_analysis.csv'
create table sales_order_data_orc
(
ORDERNUMBER int,
QUANTITYORDERED int,
PRICEEACH float,
ORDERLINENUMBER int,
SALES float,
STATUS string,
QTR_ID int,
MONTH_ID int,
YEAR_ID int,
PRODUCTLINE string,
MSRP int,
PRODUCTCODE string,
PHONE string,
CITY string,
STATE string,
POSTALCODE string,
COUNTRY string,
TERRITORY string,
CONTACTLASTNAME string,
CONTACTFIRSTNAME string,
DEALSIZE string
)
stored as orc;

# copy data from sales_order_data_csv_v1 to sales_order_data_orc
from sales_updated_csv insert overwrite into sales_updated_orc select *;

-- To perform groupby operation
select year_id, sum(sales) as total_sales from sales_updated_orc groupby year_id;

set hive.exec.reducers.bytes.per.reducers = 256000000;

set hive.exec.reducers.map = 4

set hive.mapreduce.job.reduces = 4;

-- In order to change the average load for a reducer (in bytes):                                                                                 
set hive.exec.reducers.bytes.per.reducer=<number>   
                                                                                        
-- In order to limit the maximum number of reducers:                                                                                             
set hive.exec.reducers.max=<number>                                                                                                         

-- In order to set a constant number of reducers:                                                                                                
set mapreduce.job.reduces=<number> 
  
 # change number of reducers to 3
 
set mapreduce.job.reduces=3;

create table sales_order_grouped_orc_v1 stored as orc as select year_id, sum(sales) as total_sales from sales_order_data_orc group by ye
ar_id;

hadoop fs -ls /user/hive/warehouse/sales_updated/sales_updated_csv*

create table sales_updated_orc stored as orc as select year_id, sum(sales) as total_sales from sales_order_csv group by year_id;

# after creating the table, check the number of files in hdfs location

# change number of reducers to 2
set mapreduce.job.reduces=2;


create table sales_order_grouped_orc_v2 stored as orc as select year_id, sum(sales) as total_sales from sales_order_data_orc group by ye
ar_id;

# after creating the table, check the number of files in hdfs location

select year_if from sales_order_data_orc order by year_id;

select year_if from sales_order_data_orc sort by year_id;

*************************************(PARTITION)***********************************************

# set this property if doing static partition
set hive.mapred.mode=strict;

# create table command for partition tables - for Static

create table sales_data_static_part                                                                                                     
    > (                                                                                                                                       
    > ORDERNUMBER int,                                                                                                                        
    > QUANTITYORDERED int,                                                                                                                    
    > SALES float,                                                                                                                            
    > YEAR_ID int                                                                                                                             
    > )                                                                                                                                       
    > partitioned by (COUNTRY string); 
    
# load data in static partition

insert overwrite table sales_data_static_part partition(country = 'USA') select ordernumber,quantityordered,sales,year_id from sales_ord
er_data_orc where country = 'USA';

# set this property for dynamic partioning
set hive.exec.dynamic.partition.mode=nonstrict;   


hive> create table sales_data_dynamic_part                                                                                                    
    > (
    > ORDERNUMBER int,                                                                                                                        
    > QUANTITYORDERED int,                                                                                                                    
    > SALES float,                                                                                                                            
    > YEAR_ID int                                                                                                                             
    > )
    > partitioned by (COUNTRY string); 

# load data in dynamic partition table

insert overwrite table sales_data_dynamic_part partition(country) select ordernumber,quantityordered,sales,year_id,country from sales_or
der_data_orc;
  

# multilevel partition

create table sales_data_dynamic_multilevel_part_v1                                                                                      
    > (
    > ORDERNUMBER int,                                                                                                                        
    > QUANTITYORDERED int,                                                                                                                    
    > SALES float                                                                                                                             
    > )
    > partitioned by (COUNTRY string, YEAR_ID int); 
    
# load data in multilevel partitions

insert overwrite table sales_data_dynamic_multilevel_part_v1 partition(country,year_id) select ordernumber,quantityordered,sales,country
,year_id from sales_order_data_orc;



create table sales_data_static
(
ordernumber int,
quantityordered int,
sales int,
year_id int
)
partitoned by (country string);

insert overwrite table sales_data_static partition(country = 'USA') select ordernumber, quantityordered, sales, year_id from sales_orc_utd where country = 'USA';
